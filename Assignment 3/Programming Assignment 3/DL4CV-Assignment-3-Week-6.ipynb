{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL4V Assignment 3 (Week 6)- Question",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPULGCH5hgM_"
      },
      "source": [
        "#### **Welcome to Assignment 3 on Deep Learning for Computer Vision.**\n",
        "In this assignment you will get a chance to implement basic Visualizations techniques, like- Vanilla Backprop, Integrated Gradient.\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "3. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
        "you sould not change anything else code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "4. Read documentation of each function carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwZf89BMxbIG"
      },
      "source": [
        "### Question 1\n",
        "Visualize saliency map from Pretrained Vgg19 model of a given image using \"simple Gradient\" method. Find out the mean and maximum  pixel intensity value of the generated saliency map. Note that the input image has 3 channels. To derive a single class saliency value for each pixel (i, j),  take the maximum magnitude across all colour channels.\n",
        "\n",
        "which of the following values are true?\n",
        "\n",
        "\n",
        "1.   Mean - 0.0117; Maximum - 0.7853\n",
        "2.   Mean - 0.0173; Maximum - 0.6645\n",
        "3.   Mean - 0.0279; Maximum - 0.5638\n",
        "4.   Mean - 0.0378; Maximum - 0.4726\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkAaUjsx_1aG"
      },
      "source": [
        "#IMPORTS\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "#Using VGG-19 pretrained model for image classification\n",
        "\n",
        "model = torchvision.models.vgg19(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Opening the image\n",
        "img = Image.open('/content/input.jpg')\n",
        "\n",
        "# Preprocess the image\n",
        "def preprocess(image, size=224):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((size,size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        T.Lambda(lambda x: x[None]),\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "# preprocess the image\n",
        "X = preprocess(img)\n",
        "\n",
        "### YOUR CODE STARTS HERE ###\n",
        "\n",
        "\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBsMP4u2U1oH"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Compute accumulated Attribution over all the input pixels of a given image towards a class (class id-243) output using Integrated Gradient(IG) Method. Assume baseline or reference image to be an image with all zero pixels. Also consider number of steps in IG approximation as 5 and all intermediate step images should follow linear path from baseline image to original image.\n",
        "\n",
        "which of the following value is true for the estimation of accumulated attribution over all the input pixels across all the channels?\n",
        "\n",
        "1.   0.9732\n",
        "2.   0.6931\n",
        "3.   0.8646\n",
        "4.   0.5691\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhiAE9DM_uG1"
      },
      "source": [
        "#IMPORTS\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "# Opening the image\n",
        "img = Image.open('input.jpg') \n",
        "\n",
        "# Preprocess the image\n",
        "def preprocess(image, size=224):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((size,size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        T.Lambda(lambda x: x[None]),\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "# preprocess the image\n",
        "X = preprocess(img)\n",
        "\n",
        "# we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\n",
        "X.requires_grad_()\n",
        "\n",
        "class IG():\n",
        "    \"\"\"\n",
        "        Compute attribution of classifier's output from each input pixels using \n",
        "        Integrated Gradient Methood \n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = torchvision.models.vgg19(pretrained=True) \n",
        "        self.gradients = None\n",
        "        # Put model in evaluation mode\n",
        "        self.model.eval()\n",
        "        # Hook the first layer to get the gradient\n",
        "        self.hook_layers()\n",
        "\n",
        "    def hook_layers(self):\n",
        "        def hook_function(module, grad_in, grad_out):\n",
        "            self.gradients = grad_in[0]\n",
        "\n",
        "        # Register hook to the first layer\n",
        "        first_layer = list(self.model.features._modules.items())[0][1]\n",
        "        first_layer.register_backward_hook(hook_function)\n",
        "\n",
        "    def create_images_on_linear_path(self, input_image, steps):\n",
        "        ''' Create list of all intermediate step images on a linear path\n",
        "            conneting baseline image to original input image\n",
        "        '''\n",
        "        ### YOUR CODE STARTS HERE\n",
        "        \n",
        "        ### YOUR CODE ENDS HERE\n",
        "\n",
        "    def compute_gradients(self, input_image, target_class):\n",
        "        ''' Compute gradient of model's target class output w.r.t to all input pixels'''  \n",
        "\n",
        "        ### YOUR CODE STARTS HERE\n",
        "        \n",
        "        ### YOUR CODE ENDS HERE\n",
        "\n",
        "    def compute_integrated_gradients(self, input_image, target_class, steps):\n",
        "\n",
        "        ''' Main computation of Integrated Gradient method'''\n",
        "        # Generate xbar images\n",
        "        x_list = self.create_images_on_linear_path(input_image, steps)\n",
        "        # Initialize an iamge composed of zeros\n",
        "        integrated_grads = np.zeros(input_image.size())\n",
        "        for x_image in x_list:\n",
        "            # Generate gradients from xbar images\n",
        "            single_integrated_grad = self.compute_gradients(x_image, target_class)\n",
        "            # Add rescaled grads from xbar images\n",
        "            integrated_grads = integrated_grads + single_integrated_grad/steps\n",
        "        # [0] to get rid of the first channel (1,3,224,224)\n",
        "        return integrated_grads[0]\n",
        "\n",
        "### YOUR CODE STARTS HERE\n",
        "\n",
        "### YOUR CODE ENDS HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2DfttgqCpTR"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "For a given input image, Find out the channel index and the importance(weight) score of most important feauture map (out of all the feature maps of final convolution layer of a pretrained ResNet50 model) using Grad-CAM method for the class prediction corresponds to \"highest logit score\". Note that, Grad-CAM produce final heatmap using the weighted combination of the feature map activations, where weights corresponds to importance score.\n",
        "\n",
        "\n",
        "1.   channel index - 708 ; importance score - 0.0046\n",
        "2.   channel index - 569 ; importance score - 0.0039\n",
        "3.   channel index - 1093 ; importance score - 0.0071\n",
        "4.   channel index - 211 ; importance score - 0.0009\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cxXuFWjC867"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "def process_image(img):\n",
        "    means = [0.485, 0.456, 0.406]\n",
        "    stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "    p_img = img.copy()[:, :, ::-1]\n",
        "    for i in range(3):\n",
        "        p_img[:, :, i] = p_img[:, :, i] - means[i]\n",
        "        p_img[:, :, i] = p_img[:, :, i] / stds[i]\n",
        "    p_img = np.ascontiguousarray(np.transpose(p_img, (2, 0, 1)))\n",
        "    p_img = torch.from_numpy(p_img)\n",
        "    p_img.unsqueeze_(0)\n",
        "    input = p_img.requires_grad_(True)\n",
        "    return input\n",
        "\n",
        "class Feat_Extractor():\n",
        "    \"\"\" register gradients get activations from targetted intermediate layers \"\"\"\n",
        "    def __init__(self, model, target_layers):\n",
        "        self.model = model\n",
        "        self.target_layers = target_layers\n",
        "        self.gradients = []\n",
        "\n",
        "    def save_gradient(self, grad):\n",
        "        self.gradients.append(grad)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        outputs = []\n",
        "        self.gradients = []\n",
        "        for name, module in self.model._modules.items():\n",
        "            x = module(x)\n",
        "            if name in self.target_layers:\n",
        "                x.register_hook(self.save_gradient)\n",
        "                outputs += [x]\n",
        "        return outputs, x\n",
        "\n",
        "\n",
        "class Netout():\n",
        "    \"\"\" Get network output through forward pass and get intermediate layer representation\n",
        "    and gradient computation for targeted intermediate layer  \"\"\"\n",
        "\n",
        "    def __init__(self, net, feat_module, target_layers):\n",
        "        self.model = net\n",
        "        self.feature_module = feat_module\n",
        "        self.feature_extractor = Feat_Extractor(self.feature_module, target_layers)\n",
        "\n",
        "    def get_gradients(self):\n",
        "        return self.feature_extractor.gradients\n",
        "\n",
        "    def __call__(self, x):\n",
        "        target_activations = []\n",
        "        for name, module in self.model._modules.items():\n",
        "            if module == self.feature_module:\n",
        "                target_activations, x = self.feature_extractor(x)\n",
        "\n",
        "            elif \"avgpool\" in name.lower():\n",
        "                x = module(x)\n",
        "                x = x.view(x.size(0),-1)\n",
        "    \n",
        "            else:\n",
        "                x = module(x)\n",
        "        \n",
        "        return target_activations, x\n",
        "\n",
        "\n",
        "#visualize heatmap on input image\n",
        "def visualize(img, mask):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    cam = heatmap + np.float32(img)\n",
        "    cam = cam / np.max(cam)\n",
        "    img = np.uint8(255 * cam)\n",
        "    plt.imshow(img)\n",
        "\n",
        "\n",
        "class GradientCam:\n",
        "    def __init__(self, model, feature_module, target_layer_, cuda):\n",
        "        self.model = model\n",
        "        self.feature_module = feature_module\n",
        "        self.model.eval()\n",
        "        self.cuda = cuda\n",
        "        if self.cuda:\n",
        "            self.model = model.cuda()\n",
        "\n",
        "        self.extractor = Netout(self.model, self.feature_module, target_layer_)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def __call__(self, input, index=None):\n",
        "        \n",
        "        ''' This function should Return weights corresponding to each feature map of last convolution layer.\n",
        "        Note that, linear combination of such weights with last conv layer feature map finally \n",
        "        produce the explanation map'''\n",
        "\n",
        "        ### YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        ### YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    image = cv2.imread('/content/input.jpg', 1)\n",
        "    image = np.float32(cv2.resize(image, (224, 224))) / 255\n",
        "    input = process_image(image)\n",
        "\n",
        "    net = models.resnet50(pretrained=True)\n",
        "    grad_cam = GradientCam(model=net, feature_module=net.layer4, \\\n",
        "                       target_layer_=[\"2\"], cuda=False)\n",
        "    \n",
        "\n",
        "    target_index = None\n",
        "\n",
        "    ### call to grad_cam method should return the importance vector corresponds to\n",
        "    ### each feature map of last convolution layer of pretrained Resnet50\n",
        "\n",
        "    weights, class_activation_map = grad_cam(input, target_index)\n",
        "\n",
        "    print (\"Most important feature map index: \", np.argmax(weights))\n",
        "    print (\"Its corresponding importance is: \", np.max(weights))\n",
        "\n",
        "    visualize(image, class_activation_map)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}